{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import base64\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9963"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('VOCdevkit/VOC2007/JPEGImages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('VOCdevkit/VOC2007/SegmentationObject'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob('VOCdevkit/VOC2007/JPEGImages/*.jpg')\n",
    "label_paths = glob('VOCdevkit/VOC2007/SegmentationClass/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['000032', '000033', '000039', '000042', '000061'],\n",
       " ['000001', '000002', '000003', '000004', '000005'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names = [ x.split('\\\\')[-1].split('.')[0] for x in image_paths ]\n",
    "segment_names = [ x.split('\\\\')[-1].split('.')[0] for x in label_paths ]\n",
    "segment_names[:5] , image_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8659b2972c44624bfbe6565b42527bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=632.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm_notebook(label_paths):\n",
    "    new_dir = os.path.join(os.path.dirname(path), 'new_folder')\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)\n",
    "    label = np.array(Image.open(path))\n",
    "    new_label = Image.fromarray(label)\n",
    "    new_path = os.path.join(new_dir, os.path.basename(path))\n",
    "    new_label.save(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_paths = []\n",
    "for segment_name in segment_names :\n",
    "    if segment_name in image_names :\n",
    "        new_image_paths.append(os.path.join('VOCdevkit/VOC2007/JPEGImages\\\\',(segment_name+'.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(632,\n",
       " ['VOCdevkit/VOC2007/JPEGImages\\\\000032.jpg',\n",
       "  'VOCdevkit/VOC2007/JPEGImages\\\\000033.jpg',\n",
       "  'VOCdevkit/VOC2007/JPEGImages\\\\000039.jpg',\n",
       "  'VOCdevkit/VOC2007/JPEGImages\\\\000042.jpg',\n",
       "  'VOCdevkit/VOC2007/JPEGImages\\\\000061.jpg'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_image_paths) , new_image_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 하나로 합쳤고, 클래스가 몇개 있는지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_num(lbl_paths) :\n",
    "    print(len(lbl_paths))\n",
    "    class_unique = []\n",
    "    for lbl_path in lbl_paths :\n",
    "\n",
    "        label_classes = np.unique(np.array(Image.open(lbl_path)))\n",
    "        for label_class in label_classes :\n",
    "            if label_class not in class_unique :\n",
    "                class_unique.append(label_class)\n",
    "    return class_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632\n"
     ]
    }
   ],
   "source": [
    "class_unique = class_num(label_paths)\n",
    "class_nums = len(class_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x130cdf99b08>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class num 255는 어떤걸까? 확인해보자\n",
    "path =  np.array(Image.open(label_paths[0]))\n",
    "path = np.where(path == 255, 1 , 0)\n",
    "plt.imshow(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 5\n",
    "drop_rate = 0.2\n",
    "\n",
    "input_shape = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이건 그냥 학습용 으로 올려둔겁니다 아래에 고친 함수가 새로 있습니다.\n",
    "\n",
    "\n",
    "def data_preprocess(img_path, lbl_path):\n",
    "    image_tf = tf.io.read_file(img_path)\n",
    "    image = tf.io.decode_jpeg(image_tf) / 255\n",
    "    image = tf.image.resize(image, input_shape[:2])\n",
    "    \n",
    "    label_tf = tf.io.read_file(lbl_path)\n",
    "    label = tf.io.decode_png(label_tf)\n",
    "\n",
    "    label_c, _ = tf.split(label, [1, -1], axis=-1)\n",
    "    \n",
    "    # 아까 위에서 본 테두리를 없애는 과정?\n",
    "    label_c = tf.where(label_c == 255 , tf.zeros_like(0, dtype=tf.uint8), label_c)\n",
    "    \n",
    "    \n",
    "    label_c = tf.image.resize(label_c, input_shape[:2], 'nearest')\n",
    "    label = tf.squeeze(label_c)    \n",
    "    label_onehot = tf.one_hot(label, class_nums)\n",
    "    return image, label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 것으로도학습이 돌아가긴 한다, 하지만!!! 문제는,, PIL 로 읽는 것과 tensorflow 가 읽는 값이 다르다고한다. 아래와 결과를 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281, 500, 3)\n",
      "[  0 128 192 224]\n"
     ]
    }
   ],
   "source": [
    "label_tf = tf.io.read_file(label_paths[0])\n",
    "label = tf.io.decode_png(label_tf)\n",
    "\n",
    "print(label.shape)\n",
    "label_c, _ = tf.split(label, [1, -1], axis=-1)\n",
    "\n",
    "# 아까 위에서 본 테두리를 없애는 과정?\n",
    "\n",
    "label_c = tf.where(label_c == 255 , tf.zeros_like(0, dtype=tf.uint8), label_c)\n",
    "print(np.unique(label_c))\n",
    "\n",
    "label_c = tf.image.resize(label_c, input_shape[:2], 'nearest')\n",
    "label = tf.squeeze(label_c)    \n",
    "label_onehot = tf.one_hot(label, class_nums)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0, 128, 192, 224 ?? 테두리값 255는 어디갔고 또 옆에 값들은 무엇인가??.. 심지어 shape를 보면 채널이 3개이다 ㅠㅠ 이런 시련이,,, 그래서 아래와 같이 좀 복잡하게 값을 불러와야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(img_path, lbl_path):\n",
    "    image_tf = tf.io.read_file(img_path)\n",
    "    image = tf.io.decode_jpeg(image_tf) / 255\n",
    "    image = tf.image.resize(image, input_shape[:2])\n",
    "    \n",
    "    png_bytes = tf.io.read_file(label_paths[0])\n",
    "    label = tf.py_function(lambda bytes: np.array(Image.open(label_paths[0])),[png_bytes], tf.uint8)\n",
    "    \n",
    "    # 이전것과는 다르게 shape이 (281,500,1) 이 아닌 (281,500) 으로 나오므로 reshape해줘야 한다.\n",
    "    label_c = tf.reshape(label, [281,500,1])\n",
    "\n",
    "    # 아까 위에서 본 테두리를 없애는 과정?\n",
    "    label_c = tf.where(label_c == 255 , tf.zeros_like(0, dtype=tf.uint8), label_c)\n",
    "    label_c = tf.image.resize(label_c, input_shape[:2], 'nearest')\n",
    "    label = tf.squeeze(label_c)    \n",
    "\n",
    "    label_onehot = tf.one_hot(label, class_nums-1)\n",
    "    return image, label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((new_image_paths, label_paths))\n",
    "dataset = dataset.map(data_preprocess)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 128, 128, 3]), TensorShape([4, 128, 128, 21]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image,label = next(iter(dataset))\n",
    "image.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build UNet\n",
    "inputs = layers.Input(input_shape)\n",
    "conv1 = layers.Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = layers.BatchNormalization()(conv1)\n",
    "conv1 = layers.Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "conv1 = layers.BatchNormalization()(conv1)\n",
    "conv1 = layers.Activation(\"relu\")(conv1)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = layers.Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = layers.BatchNormalization()(conv2)\n",
    "conv2 = layers.Activation(\"relu\")(conv2)\n",
    "conv2 = layers.Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "conv2 = layers.BatchNormalization()(conv2)\n",
    "conv2 = layers.Activation(\"relu\")(conv2)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = layers.Conv2D(256, 3, padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = layers.BatchNormalization()(conv3)\n",
    "conv3 = layers.Activation(\"relu\")(conv3)\n",
    "conv3 = layers.Conv2D(256, 3, padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "conv3 = layers.BatchNormalization()(conv3)\n",
    "conv3 = layers.Activation(\"relu\")(conv3)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = layers.Conv2D(512, 3, padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = layers.BatchNormalization()(conv4)\n",
    "conv4 = layers.Activation(\"relu\")(conv4)\n",
    "conv4 = layers.Conv2D(512, 3, padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "conv4 = layers.BatchNormalization()(conv4)\n",
    "conv4 = layers.Activation(\"relu\")(conv4)\n",
    "drop4 = layers.Dropout(drop_rate)(conv4)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = layers.Conv2D(1024, 3, padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = layers.BatchNormalization()(conv5)\n",
    "conv5 = layers.Activation(\"relu\")(conv5)\n",
    "conv5 = layers.Conv2D(1024, 3, padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "conv5 = layers.BatchNormalization()(conv5)\n",
    "conv5 = layers.Activation(\"relu\")(conv5)\n",
    "drop5 = layers.Dropout(drop_rate)(conv5)\n",
    "\n",
    "up6 = layers.Conv2DTranspose(1024, 2, padding='same', strides=(2, 2))(drop5)\n",
    "merge6 = layers.concatenate([drop4, up6], axis=3)\n",
    "conv6 = layers.Conv2D(512, 3, padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = layers.BatchNormalization()(conv6)\n",
    "conv6 = layers.Activation(\"relu\")(conv6)\n",
    "conv6 = layers.Conv2D(512, 3, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "conv6 = layers.BatchNormalization()(conv6)\n",
    "conv6 = layers.Activation(\"relu\")(conv6)\n",
    "\n",
    "up7 = layers.Conv2DTranspose(512, 2, padding='same', strides=(2, 2))(conv6)\n",
    "merge7 = layers.concatenate([conv3, up7], axis=3)\n",
    "conv7 = layers.Conv2D(256, 3, padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = layers.BatchNormalization()(conv7)\n",
    "conv7 = layers.Activation(\"relu\")(conv7)\n",
    "conv7 = layers.Conv2D(256, 3, padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "conv7 = layers.BatchNormalization()(conv7)\n",
    "conv7 = layers.Activation(\"relu\")(conv7)\n",
    "\n",
    "up8 = layers.Conv2DTranspose(256, 2, padding='same', strides=(2, 2))(conv7)\n",
    "merge8 = layers.concatenate([conv2, up8], axis=3)\n",
    "conv8 = layers.Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = layers.BatchNormalization()(conv8)\n",
    "conv8 = layers.Activation(\"relu\")(conv8)\n",
    "conv8 = layers.Conv2D(128, 3, padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "conv8 = layers.BatchNormalization()(conv8)\n",
    "conv8 = layers.Activation(\"relu\")(conv8)\n",
    "\n",
    "up9 = layers.Conv2DTranspose(128, 2, padding='same', strides=(2, 2))(conv8)\n",
    "merge9 = layers.concatenate([conv1, up9], axis=3)\n",
    "conv9 = layers.Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = layers.BatchNormalization()(conv9)\n",
    "conv9 = layers.Activation(\"relu\")(conv9)\n",
    "conv9 = layers.Conv2D(64, 3, padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = layers.BatchNormalization()(conv9)\n",
    "conv9 = layers.Activation(\"relu\")(conv9)\n",
    "conv9 = layers.Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "conv10 = layers.Conv2D(class_nums, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice Coefficient\n",
    "def precision(y_true, y_pred):\n",
    "    axes = tuple(range(1, len(y_pred.shape)-1))\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axes)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axes)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    return K.mean(precision)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    axes = tuple(range(1, len(y_pred.shape)-1))\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axes)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axes)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "    return K.mean(recall)\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    epsilon=1e-6\n",
    "    axes = tuple(range(1, len(y_pred.shape)-1)) \n",
    "    numerator = 2. * K.sum(y_pred * y_true, axes)\n",
    "    denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n",
    "    \n",
    "    return K.mean(numerator / (denominator + epsilon))\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    epsilon=1e-6\n",
    "    axes = tuple(range(1, len(y_pred.shape)-1)) \n",
    "    numerator = 2. * K.sum(y_pred * y_true, axes)\n",
    "    denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n",
    "    \n",
    "    return 1 - K.mean(numerator / (denominator + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=soft_dice_loss,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy', dice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9/2490 [..............................] - ETA: 1:13:11 - loss: 0.9524 - accuracy: 0.2069 - dice: 0.0476"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-73359fbe3b8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstep_per_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_per_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step_per_epochs = len(image_paths) // batch_size\n",
    "\n",
    "model.fit(dataset, steps_per_epoch=step_per_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = \"new_label\"\n",
    "if not os.path.exists(new_dir):\n",
    "    os.mkdir(new_dir)\n",
    "for path in label_paths:\n",
    "    label = np.array(Image.open(path))\n",
    "    Image.fromarray(label).save(os.path.join(os.path.dirname(path), new_dir, os.path.basename(path)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
